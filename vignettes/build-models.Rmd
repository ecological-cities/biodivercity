---
title: "Build Models"
subtitle: "Build and summarise GLMM models with processed animal and landscape data"
author: "Edwin Tan"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Build Models}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

Following the preparation of collected fauna and landscape data, this article outlines a workflow to build predictive models of animal diversity. We drew on the community ecology theory and the concept of ‘decomposing’ diversity into α-diversity and β-diversity components. A predictive model was built for each of the diversity components.

### If too many variables are present:

For this collection of articles, random forest models were first used to select variables based on their relative importance in improving model performance, i.e., averaged variable importance (Arthur et al., 2010; Li et al., 2017). The random forest algorithm is a machine learning technique that can handle and reduce the effects of overfitting, as well as the collinearity and selection bias of predictors (Hothorn et al., 2006). In the following sections, the example variables were for both α-diversity and β-diversity models were selected using the `randomForest` package.

---
## Alpha diversity models
### Building the GLM models

Species density at sampling points were modelled against the summarised landscape metrics with generalised linear mixed-effects models (GLMMs) using the `MuMIn::dredge` function. However, owing to the large number of landscape predictors at multiple buffer radii generated from the remotely
sensed and open data, variable selection has to be performed as there is a limit to the number of variables `MuMIn::dredge` is allowed to accept.

First, load the necessary packages to run the model building:

```{r load required libraries, message = FALSE, warning = FALSE, eval = FALSE}
library("biodivercity")
library("tidyverse") # to process/wrangle data
library("sf") # to process landscape data
library("tmap")
library("kableExtra")

library("lme4")
library("MuMIn")
```

```{r load biodivercity while in dev, include = FALSE}
devtools::load_all()
library("tidyverse") 
library("sf") 
library("tmap")
library("kableExtra")

library("lme4")
library("MuMIn")
```

Bird species density and landscape data for sampling points across six areas (towns) in Singapore from the example data `model_data` will be used to demonstrate the model building process in this article. In this example dataset, animal and landscape datasets as processed in the previous two articles were combined. The variable selection output using random forest is also loaded from `model_variables` to inform `MuMIn::dredge`. 

```{r load example data, eval = FALSE}
system.file("extdata", "model_data", package="biodivercity") # model_data has been filtered to match model_variables 
system.file("extdata", "model_variables", package="biodivercity")
```

Before running `MuMIn::dredge`, model constraints have to be considered to avoid combinations of variables that represented similar landscape characteristics. For example, for each land cover class, only one of each metric type could be present in the fitted model, and similar landscape predictors at different buffer radii were not allowed. To do so, `MuMIn::dredge` accepts expressions for the `subset` argument and such an object is automatically created from `model_variables` below.

```{r subset remote vars, eval = FALSE}

var_comb <- combn(model_variables$variable, 2) %>% # unique combinations of variables
  t() %>% 
  as.data.frame() %>% 
  arrange(V1) %>%
  mutate(subset = paste(V1, "&", V2))
  
# unique combinations of landscape metrics by type
lsm_comb <- landscapemetrics::list_lsm() %>% 
  dplyr::select(metric, type) %>% 
  unique() %>% 
  mutate(metric = paste0("_", metric)) %>% 
  # group_by(type) %>% 
  pivot_wider(names_from = "type", values_from = "metric") %>% 
  apply(MARGIN = 2, FUN = function(x) combn(x[[1]], 2)) %>% 
  as.data.frame() %>% 
  t() %>% 
  as.data.frame()

# get unique landscape classes
lsm_classes <- 
  str_extract(model_variables$predictor, "(?<=lsm_)([^_]*)_") %>% 
  str_remove("_") %>% 
  unique() %>% na.omit()
  
subset_vec <- c()
for(i in 1:nrow(lsm_comb)){ # extract combinations in var_comb that match rows in lsm_comb

  for(j in seq_along(lsm_classes)){

    to_subset <-
      with(var_comb,
           var_comb[grepl(glue::glue("{lsm_classes[j]}{lsm_comb$V1[i]}"), V1) &
                      grepl(glue::glue("{lsm_classes[j]}{lsm_comb$V2[i]}"), V2), ])

    to_subset_inverted <- # if the combination is the other way round
      with(var_comb,
           var_comb[grepl(glue::glue("{lsm_classes[j]}{lsm_comb$V2[i]}"), V1) &
                      grepl(glue::glue("{lsm_classes[j]}{lsm_comb$V1[i]}"), V2), ])

    if(!is.null(to_subset)){
      subset_vec <- c(subset_vec, paste(to_subset$subset))
    }

    if(!is.null(to_subset_inverted)){
      subset_vec <- c(subset_vec, paste(to_subset_inverted$subset))
    }

  }
  rm(to_subset, i, j)
}

subset_exp <- parse(text = paste0("!(", paste(subset_vec, collapse = ") & !("), ")")) # returns exp - subset doesn't accept paste
```

Model data should then be scaled before building the models.

```{r scale model_data, eval = FALSE}
# scale/center model_data

model_data <- model_data %>% 
  mutate(across(.cols = where(is.numeric) & 
                  !sprich, 
                scale))
```

For the `MuMIn::dredge` function, a global model has to be fitted as a primary input. A null model is also fitted for the `extra` argument to calculate a delta-AIC value for model selection.

```{r example dredge - global and null, eval = FALSE}
model_global <- glmer(paste("sprich", "~", paste(model_variables$variable, collapse = " + "), "+ (1|town) "),
                      family = poisson,
                      data = model_data,
                      na.action = "na.fail",
                      control = lme4::glmerControl(optimizer = "bobyqa"))

model_null <- glmer(sprich ~ 1 + (1|town),
                    family = poisson, data = model_data)
```

The `MuMIn::dredge` function is then run with `model_global`, `subset = subset_exp` and `m.lim=c(NA,9)` as model combination constraints. 

```{r example dredge - dredge, eval = FALSE}
model_glm <- dredge(model_global,
                    subset= subset_exp,
                    m.lim=c(NA,9), # max of 9 variables
                    rank="AICc",
                    extra = list(R2 = function(x) r.squaredGLMM(x, model_null)["delta", ]))

# reduce size of huge object - subset only top models 
model_glm <- subset(model_glm, 
                   delta < 8,
                   recalc.weights=TRUE)
```

```{r load dredge model object, include = FALSE}
filepath <- system.file("extdata", "models-remote-post-rf_sample.Rdata", package = "biodivercity")
load(filepath)

filepath <- system.file("extdata", "model_data.Rdata", package = "biodivercity")
load(filepath)

model_data <- model_data %>% 
  dplyr::mutate(across(.cols = where(is.numeric) & !sprich, 
                scale))
```

The resulting `model_glm` object contains all of the top models with values of ΔAIC < 8. Here, a summary of the top models with values of ΔAIC < 2 can be viewed:

```{r table of best models, echo = FALSE}
bestmodels_info <- subset(model_glm, 
                         delta < 2,
                         recalc.weights=FALSE)

to_print <- bestmodels_info %>% 
  as.data.frame() %>% 
  dplyr::select(where(function(x) any(!is.na(x)))) %>% 
  mutate(across(.cols = !df, ~round(., 3))) %>% 
  mutate(across(.cols = everything(), ~ifelse(is.na(.), "-", .)))

knitr::kable(to_print, caption = glue::glue("**Summary of best models ranked based on automated model selection from `MuMIn::dredge()` (ΔAIC < 2).**")) %>%
  kable_styling("striped") %>% scroll_box(width = "100%", height = "300px")
```

For a visual breakdown of variables in the top models, a plot of the top important variables and their sum of model weights across all models can be produced:

```{r plot of coefs, message = FALSE}
coef <- data.frame(coef(bestmodels_info)[,-1]) %>% 
  summarise(across(everything(), ~ mean(.x, na.rm = TRUE))) %>% 
  pivot_longer(everything(), names_to = "var") %>% 
  mutate(effect = ifelse(value > 0, "Positive", "Negative"))

imp <- data.frame(MuMIn::sw(bestmodels_info)) %>% 
  rename(imp = MuMIn..sw.bestmodels_info.) %>% 
  rownames_to_column("var") %>% 
  left_join(coef, by = "var") %>% 
  mutate(effect = ifelse(is.na(effect), "Mixed (factor)", effect)) %>%
  mutate(effect = factor(effect, levels = c("Positive", "Negative", "Mixed (factor)")))

ggplot(data=imp, aes(x = imp, y = reorder(var, imp), 
                     fill = effect)) + 
  geom_bar(stat = "identity") +
  labs(x = "Sum of weights", y = "Variables") +
  scale_fill_manual(values = c("#4daf4a", "#e41a1c", "#377eb8"),
                    name = "Effect")

```

```{r, include = FALSE}
rm(filepath, to_print, coef, imp)

# bestmodels <- MuMIn::get.models(bestmodels_info, subset = TRUE)
# performance::check_model(bestmodels[[1]])

rm(bestmodels_info)
```

---

<br>

## Beta diversity models
### Building the partial RDA models
Partial RDA models were used to model the relationship between animal communities and landscape predictors while considering also the inherent spatial structure of the animal communities. Similarly, variable selection by random forest was performed on the landscape variables prior to beta model building. In the following sections, the example variables were selected using the `randomForestSRC` and `MultivariateRandomForest` packages. After the first round of variable selection, the landscape predictors were summerised as Principal Component Analysis (PCA) axes while the spatial variation were quantified using Principle Coordinates of Neighbourhood Matrices (PCNM).

First, load the additional package `vegan` for beta diversity model building:

```{r load vegan, message = FALSE, warning = FALSE}
library("vegan")
```

As before, bird species density and landscape data for sampling points across six areas (towns) in Singapore will be analysed in this example. In this example dataset `beta_model_data`, animal and landscape datasets as processed in the previous two articles were combined. The variable selection output using random forest is also loaded from `beta_model_variables` to inform the principal component analysis (PCA) of the selected landscape variables later. 

```{r load data, message = FALSE, warning = FALSE}

# #Before package release:
# load("../inst/extdata/beta_model_data.Rdata")
# load("../inst/extdata/beta_model_variables.Rdata")
# load("../data/animal_observations.rda")
# load("../data/sampling_points.rda")

# Afrer package release:
filepath <- system.file("extdata", "beta_model_data.Rdata", package="biodivercity") #summarised landscape information per point
load(filepath)

filepath <- system.file("extdata", "beta_model_variables.Rdata", package="biodivercity") #variables selected from random forest
load(filepath)

data("animal_observations")
data("sampling_points")

sampling_points <- sampling_points %>% 
  filter(period == 1)
```

Next, we process the fauna datasets into acceptable formats for analyses.

```{r removing extra genus/family lvl records}
rmspp <- check_taxongrps(animal_observations, level = "point") 

animal_observations <- animal_observations %>%
  anti_join(rmspp, by = c("species" = "name","point_id", "period")) %>% 
  mutate(period = as.character(period))
```

An presence/absence community matrix is created from the observations to summarise total species incidence. 

```{r creating a presence/absence matrix, message = FALSE, warning = FALSE}
bird_com <- animal_observations %>% 
  filter(taxon == "Aves") %>%
  group_by(period, point_id, species) %>%
  summarise(n = sum(abundance)) %>%
  group_by(point_id, period) %>%
  pivot_wider(names_from = species, values_from = n) %>%
  replace(is.na(.),0) %>%
  ungroup()  %>%
  semi_join(beta_model_data, by = c("point_id", "period" = "round")) %>% # filtering for the same period
  as.data.frame(.) %>% 
  dplyr::select(-period, -point_id)

bird_com <- bird_com %>% 
  mutate(across(.cols = everything(), ~ case_when(. > 0 ~ 1,
                                                  . == 0 ~ 0))) %>% 
  select(which(colMeans(.)>0))
  
rm(rmspp)
```

After the `birds` dataset has been used to filter `bird_com`, coordinate information were added for PCNM analysis later.

```{r appending spatial information to landscape dataset, message = FALSE, warning = FALSE}
beta_model_data <- beta_model_data %>% 
  select(!c(town, round, priority, sprich)) %>% #keep only point_id and landscape variables
  arrange(point_id) %>% #sort alphabetically
  
  #adding coordinate information
  mutate(X = {(sampling_points$geometry[match(beta_model_data$point_id,sampling_points$point_id)] %>% sf::st_coordinates())[,2]}, 
         .after = point_id) %>% 
  mutate(Y = {(sampling_points$geometry[match(beta_model_data$point_id,sampling_points$point_id)] %>% sf::st_coordinates())[,1]},
         .after = X)
```

Using the variables selected by random forest, principal component analysis (PCA) is performed to summarise the landscape predictors. Only PCA axes with eigenvalues greater than one were retained. This step selects for PCA axes that account for more variance than the original variables on their own.

```{r diagnosis by PCA}

pca_birds <- beta_model_data %>% 
  dplyr::select(any_of(beta_model_variables$var)) %>% #select impt variables from RF
  prcomp(.,scale.=TRUE) #conduct pca

pca_selected_birds <- pca_birds$x[, which(pca_birds$sdev > 1)]

# biplot(pca_birds, choices=c(1,2))
```

Calculate the PCNM vectors using `Vegan::pcnm` and fit the animal community matrix against these PCNM vectors using `Vegan::rda`. To control for type I error while testing for significant predictors, significant PCNM vectors were first selected using a backwards, stepwise elimination method until all vectors has significance level smaller than the chosen significance level of 0.05 (Peres-Neto & Legendre, 2010). This was performed using `Vegan::ordistep`.

```{r PCNM, message = FALSE, warning = FALSE}
plots.xy <- cbind(beta_model_data$X, beta_model_data$Y)
raw_pcnm_birds <- pcnm(dist(plots.xy))

pcnm_scores_birds <-data.frame(scores(raw_pcnm_birds))

set.seed(123)

birds.pcnm.all <- rda(bird_com~., data = pcnm_scores_birds)
birds.pcnm.sub <- ordistep(birds.pcnm.all, direction = "backward", pout = 0.075)

```

Perform partial RDA was performed with the selected PCA axes as candidate explanatory variables and the significant PCNM vectors as covariates. Perform `Vegan::ordistep` to select for the significant PCA axes while accounting for the effects of the covariables in the model until all PCA axes has significance level smaller than the chosen significance level of 0.05. The final RDA model is fitted with the significant PC axes and PCNM vectors.

```{r stepwise selection with env vars, message = FALSE, warning = FALSE}
birds_selected <- cbind(pca_selected_birds, pcnm_scores_birds)

birds.rda.all <- update(birds.pcnm.sub, 
                        glue::glue("~. +", {paste((colnames(pca_selected_birds)), collapse=" +")}), #add selected PCA
                        data = birds_selected)

birds.rda.sub <- ordistep(birds.rda.all, direction = "backward") #assess p-value for dropping

birds.rda.sub$call

birds.rda.fin <- rda(bird_com ~ PC1 + PC2 + PC4 + PC6 + PC7 + PC8 + Condition(PCNM1 + PCNM2 + PCNM3 + PCNM4 + PCNM5), data = birds_selected)

```

The predictive β-diversity model also requires information on the average probability of each species occurring across all points.

```{r p-hats}
# fitted_126 <- fitted(birds1.rda.fin, model = "CCA")
p_hats_birds <- apply(bird_com, 2, mean)
p_hats_birds
```

The PCA axes, PNCM vectors, final RDA model and probability of species occurence are saved out to be applied in the subsequent apply model section.

```{r save beta model objs, eval = FALSE}
save(pca_birds,
     raw_pcnm_birds,
     birds.rda.fin, 
     p_hats_birds,
     file = "./your/working/directory/beta_model_birds.Rdata")
```

---

## References

Arthur AD, Li J, Henry S & Cunningham SA (2010) Influence of woody vegetation on pollinator densities in oilseed Brassica fields in an Australian temperate landscape. _Basic and Applied Ecology_, _11_(5): 406–414.

Hothorn T, Hornik K & Zeileis A (2006) Unbiased recursive partitioning: A conditional inference framework. _Journal of Computational and Graphical Statistics_, _15_(3): 651–674.

Li J, Alvarez B, Siwabessy J, Tran M, Huang Z, Przeslawski R, Radke L, Howard F & Nichol S (2017) Application of random forest and generalised linear model and their hybrid methods with geostatistical techniques to count data: Predicting sponge species richness. _Environmental Modelling and Software_, _97_: 112–129.
